{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Firstly the necessary libraries are loaded including pandas, scipy and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The cleansed dataset is loaded from a csv and the top rows are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>103.08</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4909 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0          1  67.0             0              1             1          2   \n",
       "1          1  80.0             0              1             1          2   \n",
       "2          0  49.0             0              0             1          2   \n",
       "3          0  79.0             1              0             1          3   \n",
       "4          1  81.0             0              0             1          2   \n",
       "...      ...   ...           ...            ...           ...        ...   \n",
       "4904       0  13.0             0              0             0          4   \n",
       "4905       0  81.0             0              0             1          3   \n",
       "4906       0  35.0             0              0             1          3   \n",
       "4907       1  51.0             0              0             1          2   \n",
       "4908       0  44.0             0              0             1          0   \n",
       "\n",
       "      Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0                  1             228.69  36.6               1       1  \n",
       "1                  0             105.92  32.5               2       1  \n",
       "2                  1             171.23  34.4               3       1  \n",
       "3                  0             174.12  24.0               2       1  \n",
       "4                  1             186.21  29.0               1       1  \n",
       "...              ...                ...   ...             ...     ...  \n",
       "4904               0             103.08  18.6               0       0  \n",
       "4905               1             125.20  40.0               2       0  \n",
       "4906               0              82.99  30.6               2       0  \n",
       "4907               0             166.29  25.6               1       0  \n",
       "4908               1              85.28  26.2               0       0  \n",
       "\n",
       "[4909 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training dataset\n",
    "df_stroke = pd.read_csv('data/cleansed-healthcare-dataset-stroke-data.csv',delimiter=',',header='infer')\n",
    "df_stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The features in the dataset are seperated from the label and print the values of the first 4 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 \n",
      "  Features: [1.0, 67.0, 0.0, 1.0, 1.0, 2.0, 1.0, 228.69, 36.6, 1.0] \n",
      "  Label: 1\n",
      "Patient 2 \n",
      "  Features: [1.0, 80.0, 0.0, 1.0, 1.0, 2.0, 0.0, 105.92, 32.5, 2.0] \n",
      "  Label: 1\n",
      "Patient 3 \n",
      "  Features: [0.0, 49.0, 0.0, 0.0, 1.0, 2.0, 1.0, 171.23, 34.4, 3.0] \n",
      "  Label: 1\n",
      "Patient 4 \n",
      "  Features: [0.0, 79.0, 1.0, 0.0, 1.0, 3.0, 0.0, 174.12, 24.0, 2.0] \n",
      "  Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
    "       'smoking_status']\n",
    "label = 'stroke'\n",
    "X, y = df_stroke[features].values, df_stroke[label].values\n",
    "\n",
    "for n in range(0,4):\n",
    "    print(\"Patient\", str(n+1), \"\\n  Features:\",list(X[n]), \"\\n  Label:\", y[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The dataset is split into a training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cases: 34360\n",
      "Test cases: 14730\n"
     ]
    }
   ],
   "source": [
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training cases: %d\\nTest cases: %d' % (X_train.size, X_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The training dataset is used to train the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100.0, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Set regularization rate\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The testing dataset is used to test the machine learning model that was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [0 0 0 ... 0 0 0]\n",
      "Actual labels:     [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. The accuracy of the model is determined from using the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.9633401221995926\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create a Scikit-Learn *classification report* from the testing dataset\n",
    "The classification report includes the following metrics for each class  (0 and 1)\n",
    "* *Precision*: Of the predictons the model made for this class, what proportion were correct?\n",
    "* *Recall*: Out of all of the instances of this class in the test dataset, how many did the model identify?\n",
    "* *F1-Score*: An average metric that takes both precision and recall into account.\n",
    "* *Support*: How many instances of this class are there in the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1418\n",
      "           1       1.00      0.02      0.04        55\n",
      "\n",
      "    accuracy                           0.96      1473\n",
      "   macro avg       0.98      0.51      0.51      1473\n",
      "weighted avg       0.96      0.96      0.95      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Identify the **precision_score** and **recall_score** metrics to answer the following two questions respectively\n",
    "\n",
    "\n",
    "- Q1 Of all the patients the model predicted will have a stroke, how many had a stroke?\n",
    "- Q2 Of all the ptients that are had a stroke, how many did the model identify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Precision (Q1): 1.0\n",
      "Overall Recall (Q2): 0.01818181818181818\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Precision (Q1):\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall (Q2):\",recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Tabulate a confusion matrix\n",
    "\n",
    "The confusion matric has the following structure: \n",
    "\n",
    "<table style=\"border: 1px solid black;\">\n",
    "    <tr style=\"border: 1px solid black;\">\n",
    "        <td style=\"border: 1px solid black;color: black;\" bgcolor=\"lightgray\">True Negatives</td><td style=\"border: 1px solid black;color: black;\" bgcolor=\"white\">False Positives</td>\n",
    "    </tr>\n",
    "    <tr style=\"border: 1px solid black;\">\n",
    "        <td style=\"border: 1px solid black;color: black;\" bgcolor=\"white\">False Negatives</td><td style=\"border: 1px solid black;color: black;\" bgcolor=\"lightgray\">True Positives</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Whereby the metrics mean:\n",
    "* *True Positives*: The predicted label and the actual label are both 1.\n",
    "* *False Positives*: The predicted label is 1, but the actual label is 0.\n",
    "* *False Negatives*: The predicted label is 0, but the actual label is 1.\n",
    "* *True Negatives*: The predicted label and the actual label are both 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1324  108]\n",
      " [ 197  158]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create a received operator characteristic (ROC) chart\n",
    "\n",
    "The decision to score a prediction as a 1 or a 0 depends on the threshold to which the predicted probabilties are compared. If we were to change the threshold, it would affect the predictions; and therefore change the metrics in the confusion matrix. A common way to evaluate a classifier is to examine the *true positive rate* (which is another name for recall) and the *false positive rate* for a range of possible thresholds. These rates are then plotted against all possible thresholds to form a chart known as a *received operator characteristic (ROC) chart*, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC chart shows the curve of the true and false positive rates for different threshold values between 0 and 1. A perfect classifier would have a curve that goes straight up the left side and straight across the top. The diagonal line across the chart represents the probability of predicting correctly with a 50/50 random prediction; so you obviously want the curve to be higher than that (or your model is no better than simply guessing!).\n",
    "\n",
    "## 12. Identify the area under the curve (AUC)\n",
    "The area under the curve (AUC) is a value between 0 and 1 that quantifies the overall performance of the model. The closer to 1 this value is, the better the model. Once again, scikit-Learn includes a function to calculate this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8586395467778739\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Perform preprocessing in a pipeline\n",
    "\n",
    "In this case, the ROC curve and its AUC indicate that the model performs better than a random guess which is not bad considering we performed very little preprocessing of the data.\n",
    "\n",
    "In practice, it's common to perform some preprocessing of the data to make it easier for the algorithm to fit a model to it. There's a huge range of preprocessing transformations you can perform to get your data ready for modeling, but we'll limit ourselves to a few common techniques:\n",
    "\n",
    "- Scaling numeric features so they're on the same scale. This prevents feaures with large values from producing coefficients that disproportionately affect the predictions.\n",
    "- Encoding categorical variables. For example, by using a *one hot encoding* technique you can create individual binary (true/false) features for each possible category value.\n",
    "\n",
    "To apply these preprocessing transformations, we'll make use of a Scikit-Learn feature named *pipelines*. These enable us to define a set of preprocessing steps that end with an algorithm. You can then fit the entire pipeline to the data, so that the model encapsulates all of the preprocessing steps as well as the regression algorithm. This is useful, because when we want to use the model to predict values from new data, we need to apply the same transformations (based on the same statistical distributions and catagory encodings used with the training data).\n",
    "\n",
    ">**Note**: The term *pipeline* is used extensively in machine learning, often to mean very different things! In this context, we're using it to refer to pipeline objects in Scikit-Learn, but you may see it used elsewhere to mean something else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  [1, 7, 8]),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  [0, 2, 3, 4, 5, 6, 9])])),\n",
      "                ('logregressor',\n",
      "                 LogisticRegression(C=100.0, solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n",
    "numeric_features = [1,7,8]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode the Age column)\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 9]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('logregressor', LogisticRegression(C=1/reg, solver=\"liblinear\"))])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a logistic regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline encapsulates the preprocessing steps as well as model training.\n",
    "\n",
    "## 14. Use the model trained by this pipeline to predict labels for our test set, and compare the performance metrics with the basic model we created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1324  108]\n",
      " [ 197  158]] \n",
      "\n",
      "Accuracy: 0.8293228875209849\n",
      "Overall Precision: 0.5939849624060151\n",
      "Overall Recall: 0.4450704225352113\n",
      "AUC: 0.8586395467778739\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions from test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Get evaluation metrics\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "y_scores = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. As even with the pipeline the Overall Recall is very low we will re look at the dataset used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4700\n",
       "1    1254\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stroke['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. The poor overall recall is likely due to low volume of data on stroke patients in our dataset. Therefore we will multiple the stoke data by 6 and retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7524\n",
       "0    4700\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stroke_true_positives = df_stroke['stroke'] == 1\n",
    "df_try = df_stroke[df_stroke_true_positives]\n",
    "df_stroke=df_stroke.append([df_try]*5)\n",
    "df_stroke['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. The model will be retrained on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 \n",
      "  Features: [1.0, 67.0, 0.0, 1.0, 1.0, 2.0, 1.0, 228.69, 36.6, 1.0] \n",
      "  Label: 1\n",
      "Patient 2 \n",
      "  Features: [1.0, 80.0, 0.0, 1.0, 1.0, 2.0, 0.0, 105.92, 32.5, 2.0] \n",
      "  Label: 1\n",
      "Patient 3 \n",
      "  Features: [0.0, 49.0, 0.0, 0.0, 1.0, 2.0, 1.0, 171.23, 34.4, 3.0] \n",
      "  Label: 1\n",
      "Patient 4 \n",
      "  Features: [0.0, 79.0, 1.0, 0.0, 1.0, 3.0, 0.0, 174.12, 24.0, 2.0] \n",
      "  Label: 1\n",
      "Training cases: 85560\n",
      "Test cases: 36680\n",
      "LogisticRegression(C=100.0, solver='liblinear')\n",
      "Predicted labels:  [1 1 0 ... 0 1 1]\n",
      "Actual labels:     [1 1 1 ... 0 1 1]\n",
      "The accuracy is:  0.7949836423118866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70      1398\n",
      "           1       0.80      0.89      0.84      2270\n",
      "\n",
      "    accuracy                           0.79      3668\n",
      "   macro avg       0.79      0.76      0.77      3668\n",
      "weighted avg       0.79      0.79      0.79      3668\n",
      "\n",
      "Overall Precision (Q1): 0.8002373417721519\n",
      "Overall Recall (Q2): 0.8911894273127753\n",
      "[[ 893  505]\n",
      " [ 247 2023]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3668, 1787]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-2599b673a5da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# calculate ROC curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# plot ROC curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \"\"\"\n\u001b[0;32m    913\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 914\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 263\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3668, 1787]"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
    "       'smoking_status']\n",
    "label = 'stroke'\n",
    "X, y = df_stroke[features].values, df_stroke[label].values\n",
    "\n",
    "for n in range(0,4):\n",
    "    print(\"Patient\", str(n+1), \"\\n  Features:\",list(X[n]), \"\\n  Label:\", y[n])\n",
    "    \n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training cases: %d\\nTest cases: %d' % (X_train.size, X_test.size))\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)\n",
    "\n",
    "print('The accuracy is: ', accuracy_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Overall Precision (Q1):\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall (Q2):\",recall_score(y_test, predictions))\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n",
    "numeric_features = [1,7,8]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode the Age column)\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 9]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('logregressor', LogisticRegression(C=1/reg, solver=\"liblinear\"))])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a logistic regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)\n",
    "\n",
    "# Get predictions from test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Get evaluation metrics\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "y_scores = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look a little better, so clearly preprocessing the data has made a difference.\n",
    "\n",
    "### Try a different algorithm\n",
    "\n",
    "Now let's try a different algorithm. Previously we used a logistic regression algorithm, which is a *linear* algorithm. There are many kinds of classification algorithm we could try, including:\n",
    "\n",
    "- **Support Vector Machine algorithms**: Algorithms that define a *hyperplane* that separates classes.\n",
    "- **Tree-based algorithms**: Algorithms that build a decision tree to reach a prediction\n",
    "- **Ensemble algorithms**: Algorithms that combine the outputs of multiple base algorithms to improve generalizability.\n",
    "\n",
    "This time, We'll use the same preprocessing steps as before, but we'll train the model using an *ensemble* algorithm named *Random Forest* that combines the outputs of multiple random decision trees (for more details, see the [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  [1, 7, 8]),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  [0, 2, 3, 4, 5, 6, 9])])),\n",
      "                ('logregressor', RandomForestClassifier())])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('logregressor', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# fit the pipeline to train a random forest model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the performance metrics for the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1370   28]\n",
      " [   0 2270]] \n",
      "\n",
      "Accuracy: 0.9923664122137404\n",
      "Overall Precision: 0.9878154917319408\n",
      "Overall Recall: 1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3668, 1787]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-2a269e3acf63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Overall Precision:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Overall Recall:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nAUC: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    543\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    544\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    546\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[1;32m--> 331\u001b[1;33m                             sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    332\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \"\"\"\n\u001b[0;32m    913\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 914\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 263\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3668, 1787]"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('\\nAUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "y_scores = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better!\n",
    "\n",
    "### Use the Model for Inferencing\n",
    "Now that we have a reasonably useful trained model, we can save it for use later to predict labels for new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/stroke_model.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = './models/stroke_model.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have some new observations for which the label is unknown, we can load the model and use it to predict values for the unknown label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample: [2.0, 180.0, 74.0, 24.0, 21.0, 23.9091702, 1.488172308, 22.0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but ColumnTransformer is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-4ea43a0afc89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Get a prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# The model returns an array of predictions - one for each set of features submitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         if (self._feature_names_in is not None and\n\u001b[0;32m    559\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             raise ValueError(\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8 features, but ColumnTransformer is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "model = joblib.load(filename)\n",
    "\n",
    "# predict on a new sample\n",
    "# The model accepts an array of feature arrays (so you can predict the classes of multiple patients in a single call)\n",
    "# We'll create an array with a single array of features, representing one patient\n",
    "X_new = np.array([[2,180,74,24,21,23.9091702,1.488172308,22]])\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Get a prediction\n",
    "pred = model.predict(X_new)\n",
    "\n",
    "# The model returns an array of predictions - one for each set of features submitted\n",
    "# In our case, we only submitted one patient, so our prediction is the first one in the resulting array.\n",
    "print('Predicted class is {}'.format(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
