{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Tuning the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The libraries were successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, make_scorer, precision_recall_curve, precision_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "import ipywidgets as widgets\n",
    "import joblib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "plt.style.use(\"ggplot\")\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "print(\"The libraries were successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0       1  67.0             0              1             1          2   \n",
       "1       1  80.0             0              1             1          2   \n",
       "2       0  49.0             0              0             1          2   \n",
       "3       0  79.0             1              0             1          3   \n",
       "4       1  81.0             0              0             1          2   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             105.92  32.5               2       1  \n",
       "2               1             171.23  34.4               3       1  \n",
       "3               0             174.12  24.0               2       1  \n",
       "4               1             186.21  29.0               1       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('data/cleansed-healthcare-dataset-stroke-data.csv',delimiter=',',header='infer')\n",
    "# Display top rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cases: 34360\n",
      "Test cases: 14730\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
    "       'smoking_status']\n",
    "label = 'stroke'\n",
    "X, y = df[features].values, df[label].values\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "print('Training cases: %d\\nTest cases: %d' % (X_train.size, X_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Grid Search Function to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_wrapper(refit_score='precision_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    #  Define grid search\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    \n",
    "    # Train the models \n",
    "    grid_search.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Test the models\n",
    "    y_pred = grid_search.predict(X_test.values)\n",
    "    \n",
    "    # Print the best hyperparameters\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistic Regression Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       " 'dual': [True, False],\n",
       " 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
       " 'C': [1, 10, 100, 1000, 10000],\n",
       " 'fit_intercept': [True, False],\n",
       " 'intercept_scaling': [0.05, 0.075, 0.1, 0.125, 0.15],\n",
       " 'class_weight': ['balanced'],\n",
       " 'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
       " 'max_iter': [75, 100, 125, 150, 175, 200],\n",
       " 'multi_class': ['auto', 'ovr', 'multinomial'],\n",
       " 'warm_start': [True, False]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "reg = 0.01\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# Define models hyperparameters\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'dual' : [True, False],\n",
    "    'tol' : [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    'C' : [1, 10, 100, 1000, 10000],\n",
    "    'fit_intercept' :[True, False],\n",
    "    'intercept_scaling' : [0.05, 0.075, 0.1, 0.125, 0.15],\n",
    "    'class_weight' : ['balanced'],\n",
    "    'solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [75, 100, 125, 150, 175, 200],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'warm_start' : [True, False]\n",
    "}\n",
    "\n",
    "# Define scores to test\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 1\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'dual' : [True, False],\n",
    "    'tol' : [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    'C' : [90, 100, 110],\n",
    "    'fit_intercept' :[True, False],\n",
    "    'intercept_scaling' : [0.025, 0.05, 0.055],\n",
    "    'class_weight' : ['balanced'],\n",
    "    'solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [160, 175, 180],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'warm_start' : [True, False]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 2\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'dual' : [True, False],\n",
    "    'tol' : [0.0000001, 0.000001, 0.00001, 0.0001],\n",
    "    'C' : [99, 100, 101],\n",
    "    'fit_intercept' :[True, False],\n",
    "    'intercept_scaling' : [0.01, 0.015, 0.02, 0.025, 0.03],\n",
    "    'class_weight' : ['balanced'],\n",
    "    'solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [174, 175, 176],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'warm_start' : [True, False]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 3\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'dual' : [True, False],\n",
    "    'tol' : [0.000000001, 0.00000001, 0.0000001],\n",
    "    'C' : [99, 100, 101],\n",
    "    'fit_intercept' :[True, False],\n",
    "    'intercept_scaling' : [0.001, 0.0075, 0.01],\n",
    "    'class_weight' : ['balanced'],\n",
    "    'solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [174, 175, 176],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'warm_start' : [True, False]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 4\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'penalty' : ['l2'],\n",
    "    'dual' : [False],\n",
    "    'tol' : [0.000000001, 0.0000000001, 0.00000000001],\n",
    "    'C' : [100],\n",
    "    'fit_intercept' :[True],\n",
    "    'intercept_scaling' : [0.001,0.0001,0.00001],\n",
    "    'class_weight' : ['balanced'],\n",
    "    'solver' : ['saga'],\n",
    "    'max_iter' : [175],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'warm_start' : [True]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 5\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "\n",
    "param_grid = {\n",
    "    'penalty' : ['l2'],\n",
    "    'dual' : [False],\n",
    "    'tol' : [0.000000001, 0.0000000011, 0.0000000009],\n",
    "    'C' : [100],\n",
    "    'fit_intercept' :[True],\n",
    "    'intercept_scaling' : [0.001,0.0011,0.0009],\n",
    "    'class_weight' : ['balanced'],\n",
    "    'solver' : ['saga'],\n",
    "    'max_iter' : [175],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'warm_start' : [True]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 6\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define models hyperparameters\n",
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [2, 3, 4, 5], \n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'n_estimators' : [75, 100, 125, 150, 175],\n",
    "    'max_depth': [10, 15, 20, 25, 30],\n",
    "    'max_features': [8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 1\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [70, 75, 80],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 2\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [74, 75, 76],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 3\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [72, 73, 74],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}\n",
    "\n",
    "print(\"Round 4\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [70, 71, 72],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 5\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KNN Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Define models hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 10],\n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size' : [10, 30, 50],\n",
    "    'p': [1, 2],\n",
    "    'n_jobs': [1, 5, 10]\n",
    "}\n",
    "\n",
    "print(\"Round 1\")\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 3],\n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size' : [5, 10, 15],\n",
    "    'p': [1, 2, 3],\n",
    "    'n_jobs': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 2\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2],\n",
    "    'weights': ['uniform'], \n",
    "    'algorithm': ['auto'],\n",
    "    'leaf_size' : [4, 5, 6],\n",
    "    'p': [1, 2, 3],\n",
    "    'n_jobs': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 3\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2],\n",
    "    'weights': ['uniform'], \n",
    "    'algorithm': ['auto'],\n",
    "    'leaf_size' : [1, 2, 3, 4],\n",
    "    'p': [1, 2, 3],\n",
    "    'n_jobs': [1, 2]\n",
    "}\n",
    "\n",
    "print(\"Round 4\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SVC Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "clf = SVC(random_state=0, probability=True)\n",
    "\n",
    "# Define models hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "    'degree': [1, 3, 5],\n",
    "    'gamma' : ['scale', 'auto'],\n",
    "    'coef0': [0, 1],\n",
    "    'shrinking': [True, False],\n",
    "    'tol': [0.00001, 0.001, 0.1],\n",
    "    'cache_size': [100, 200, 300],\n",
    "    'verbose': [True, False],\n",
    "    'max_iter': [1, 3, 5],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'break_ties': [True, False]\n",
    "}\n",
    "\n",
    "print(\"Round 1\")\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new hyperparameters\n",
    "param_grid = {'C': [0.01, 0.1, 0.5],\n",
    " 'kernel': ['sigmoid'],\n",
    " 'degree': [0, 1, 2],\n",
    " 'gamma': ['auto'],\n",
    " 'coef0': [0],\n",
    " 'shrinking': [True],\n",
    " 'tol': [1.00000005, 1.0000005, 1.000005],\n",
    " 'cache_size': [50, 100, 150],\n",
    " 'verbose': [True],\n",
    " 'max_iter': [0, 1, 2],\n",
    " 'decision_function_shape': ['ovr'],\n",
    " 'break_ties': [True]}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for recall_score\n",
    "print(\"Round 2\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "    'degree': [1, 3, 5],\n",
    "    'gamma' : ['scale', 'auto'],\n",
    "    'coef0': [0, 1],\n",
    "    'shrinking': [True, False],\n",
    "    'tol': [0.00001, 0.001, 0.1],\n",
    "    'cache_size': [100, 200, 300],\n",
    "    'verbose': [True, False],\n",
    "    'max_iter': [1, 3, 5],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'break_ties': [True, False]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for precision_score\n",
    "print(\"Round 3\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1],\n",
    "    'kernel': ['poly'], \n",
    "    'degree': [5, 10, 15],\n",
    "    'gamma' : ['auto'],\n",
    "    'coef0': [0],\n",
    "    'shrinking': [True],\n",
    "    'tol': [0.0000001, 0.000001, 0.00001],\n",
    "    'cache_size': [50, 100, 150],\n",
    "    'verbose': [True],\n",
    "    'max_iter': [5, 10, 15],\n",
    "    'decision_function_shape': ['ovr'],\n",
    "    'break_ties': [True]\n",
    "}\n",
    "\n",
    "# Perform grid search to identify best hyperparameters for precision_score\n",
    "print(\"Round 4\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define models hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear'], \n",
    "    'degree': [1, 3, 5],\n",
    "    'gamma' : ['scale', 'auto'],\n",
    "    'coef0': [0, 1],\n",
    "    'shrinking': [True, False],\n",
    "    'tol': [0.00001, 0.001, 0.1],\n",
    "    'cache_size': [100, 200, 300],\n",
    "    'verbose': [True, False],\n",
    "    'max_iter': [1, 3, 5],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'break_ties': [True, False]\n",
    "}\n",
    "\n",
    "print(\"Round 5\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
