{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Tuning the RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The libraries were successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, make_scorer, precision_recall_curve, precision_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "import ipywidgets as widgets\n",
    "import joblib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "print(\"The libraries were successfully loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>103.08</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4909 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0          1  67.0             0              1             1          2   \n",
       "1          1  80.0             0              1             1          2   \n",
       "2          0  49.0             0              0             1          2   \n",
       "3          0  79.0             1              0             1          3   \n",
       "4          1  81.0             0              0             1          2   \n",
       "...      ...   ...           ...            ...           ...        ...   \n",
       "4904       0  13.0             0              0             0          4   \n",
       "4905       0  81.0             0              0             1          3   \n",
       "4906       0  35.0             0              0             1          3   \n",
       "4907       1  51.0             0              0             1          2   \n",
       "4908       0  44.0             0              0             1          0   \n",
       "\n",
       "      Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0                  1             228.69  36.6               1       1  \n",
       "1                  0             105.92  32.5               2       1  \n",
       "2                  1             171.23  34.4               3       1  \n",
       "3                  0             174.12  24.0               2       1  \n",
       "4                  1             186.21  29.0               1       1  \n",
       "...              ...                ...   ...             ...     ...  \n",
       "4904               0             103.08  18.6               0       0  \n",
       "4905               1             125.20  40.0               2       0  \n",
       "4906               0              82.99  30.6               2       0  \n",
       "4907               0             166.29  25.6               1       0  \n",
       "4908               1              85.28  26.2               0       0  \n",
       "\n",
       "[4909 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleansed-healthcare-dataset-stroke-data.csv',delimiter=',',header='infer')\n",
    "\n",
    "# mimic the pipline for numerical variables\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#x = pd.DataFrame(df[\"age\"], columns = [\"age\"])\n",
    "#x[\"avg_glucose_level\"] = df[\"avg_glucose_level\"]\n",
    "#x[\"bmi\"] = df[\"bmi\"]\n",
    "\n",
    "#scaled_data = scaler.fit_transform(x)\n",
    "#scaled_data = pd.DataFrame(scaled_data)\n",
    "\n",
    "#df[\"age\"] = scaled_data[0]\n",
    "#df[\"avg_glucose_level\"] = scaled_data[1]\n",
    "#df[\"bmi\"] = scaled_data[2]\n",
    "\n",
    "# mimic the peipline for categorical variables \n",
    "#encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#y = pd.DataFrame(df[\"gender\"], columns = [\"gender\"])\n",
    "#y[\"hypertension\"] = df[\"hypertension\"]\n",
    "#y[\"heart_disease\"] = df[\"heart_disease\"]\n",
    "#y[\"ever_married\"] = df[\"ever_married\"]\n",
    "#y[\"work_type\"] = df[\"work_type\"]\n",
    "#y[\"Residence_type\"] = df[\"Residence_type\"]\n",
    "#y[\"smoking_status\"] = df[\"smoking_status\"]\n",
    "\n",
    "#encoder_data = encoder.fit_transform(y)\n",
    "#encoder_data = pd.DataFrame(encoder_data)\n",
    "\n",
    "#df[\"gender\"] = encoder_data[0]\n",
    "#df[\"hypertension\"] = encoder_data[1]\n",
    "#df[\"heart_disease\"] = encoder_data[2]\n",
    "#df[\"ever_married\"] = encoder_data[3]\n",
    "#df[\"work_type\"] = encoder_data[4]\n",
    "#df[\"Residence_type\"] = encoder_data[5]\n",
    "#df[\"smoking_status\"] = encoder_data[6]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cases: 34360\n",
      "Test cases: 14730\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
    "       'smoking_status']\n",
    "label = 'stroke'\n",
    "X, y = df[features].values, df[label].values\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "print('Training cases: %d\\nTest cases: %d' % (X_train.size, X_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the RandomForestClassifier parameters to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': [False, True],\n",
       " 'min_samples_split': [2, 3, 4, 5],\n",
       " 'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       " 'n_estimators': [75, 100, 125, 150, 175],\n",
       " 'max_depth': [10, 15, 20, 25, 30],\n",
       " 'max_features': [8, 9, 10, 11]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First build a generic classifier and setup a parameter grid; random forests have many tunable parameters, which make it suitable for GridSearchCV. The scorers dictionary can be used as the scoring argument in GridSearchCV. When multiple scores are passed, GridSearchCV.cv_results_ will return scoring metrics for each of the score types provided.\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [2, 3, 4, 5], \n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'n_estimators' : [75, 100, 125, 150, 175],\n",
    "    'max_depth': [10, 15, 20, 25, 30],\n",
    "    'max_features': [8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_wrapper(refit_score='precision_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_test.values)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')\n",
    "grid_search_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "results = results.sort_values(by='mean_test_precision_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test to see which parameters achieve the largest recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.06357143 0.06535714 0.04861111 ...        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [ 1.  1.  1. ... nan nan nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.03291667 0.03291667 0.02625    ...        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.77273486 0.7698363  0.77345949 ...        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.94062987 0.94004763 0.93975693 ...        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.98981374 0.98968438 0.9898461  ...        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'bootstrap': False, 'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 75}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1345        73\n",
      "pos        46         9\n",
      "Best params for recall_score\n",
      "{'max_depth': 20, 'max_features': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1410         8\n",
      "pos        52         3\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [70, 75, 80],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.08078866 0.08112956 0.08078866\n",
      " 0.06938154 0.06738858 0.06892857        nan        nan        nan\n",
      " 0.10871906 0.10871906 0.11053724 0.10871906 0.10871906 0.11053724\n",
      "        nan        nan        nan 0.07805736 0.08235994 0.07610994\n",
      " 0.07997899 0.07976254 0.07997899        nan        nan        nan\n",
      " 0.08805556 0.09305556 0.09305556 0.08805556 0.09305556 0.09305556\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.0700887  0.07330128 0.07307692\n",
      " 0.06915043 0.06772949 0.07002747        nan        nan        nan\n",
      " 0.09760795 0.09760795 0.10134921 0.09760795 0.09760795 0.10134921\n",
      "        nan        nan        nan 0.08412879 0.08759804 0.07732207\n",
      " 0.07331232 0.07309587 0.07331232        nan        nan        nan\n",
      " 0.08583333 0.09083333 0.09261905 0.08583333 0.09083333 0.09261905\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.06865079 0.06665968 0.06754643\n",
      " 0.07734488 0.07734488 0.07143579        nan        nan        nan\n",
      " 0.09760795 0.09760795 0.10134921 0.09760795 0.09760795 0.10134921\n",
      "        nan        nan        nan 0.07889069 0.08319328 0.07732207\n",
      " 0.07997899 0.07976254 0.07997899        nan        nan        nan\n",
      " 0.08761905 0.09261905 0.09261905 0.08761905 0.09261905 0.09261905\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.05       0.         0.         0.05       0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.05       0.         0.         0.05       0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.05       0.         0.         0.05       0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98638464 0.98637362 0.98563917 0.98638464 0.98637362 0.98563917\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93603745 0.93596506 0.93596506 0.93603745 0.93596506 0.93596506\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98627675 0.98560466 0.98554457 0.98627675 0.98560466 0.98554457\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93536551 0.93529312 0.93529312 0.93536551 0.93529312 0.93529312\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9855387  0.98555659 0.98554457 0.9855387  0.98555659 0.98554457\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93542524 0.93535284 0.93535284 0.93542524 0.93535284 0.93535284\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99886364 0.99888889 0.9988764  0.99886364 0.99888889 0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99886364 0.99888889 0.9988764  0.99886364 0.99888889 0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99886364 0.99888889 0.9988764  0.99886364 0.99888889 0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.07125    0.07125    0.07125\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333\n",
      "        nan        nan        nan 0.08375    0.09041667 0.08375\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.06458333 0.07125    0.07125    0.06458333 0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.065      0.065\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333\n",
      "        nan        nan        nan 0.09       0.09666667 0.08375\n",
      " 0.07125    0.07125    0.07125           nan        nan        nan\n",
      " 0.06458333 0.07125    0.07125    0.06458333 0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.05833333 0.05833333\n",
      " 0.06458333 0.06458333 0.05833333        nan        nan        nan\n",
      " 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333\n",
      "        nan        nan        nan 0.08375    0.09041667 0.08375\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.06458333 0.07125    0.07125    0.06458333 0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.00666667 0.         0.         0.00666667 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.00666667 0.         0.         0.00666667 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.00666667 0.         0.         0.00666667 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92278177 0.9235012  0.92638932 0.92278177 0.9235012  0.92638932\n",
      "        nan        nan        nan 0.99710666 0.99710666 0.99710666\n",
      " 0.90907622 0.90907622 0.90907622        nan        nan        nan\n",
      " 0.70053696 0.69981754 0.69981754 0.70053696 0.69981754 0.69981754\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92204671 0.92421541 0.9242102  0.92204671 0.92421541 0.9242102\n",
      "        nan        nan        nan 0.99927536 0.99927536 1.\n",
      " 0.91052549 0.91052549 0.91052549        nan        nan        nan\n",
      " 0.70416015 0.70344073 0.70344073 0.70416015 0.70344073 0.70344073\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92132207 0.92276613 0.9242102  0.92132207 0.92276613 0.9242102\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.91125013 0.91125013 0.91125013        nan        nan        nan\n",
      " 0.70488479 0.70416536 0.70416536 0.70488479 0.70416536 0.70416536\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98988114 0.99711188 0.99855594\n",
      " 0.97761964 0.9797727  0.9819414         nan        nan        nan\n",
      " 0.60962882 0.60748618 0.60602648 0.60962882 0.60748618 0.60602648\n",
      "        nan        nan        nan 0.98916693 0.99638202 0.99855594\n",
      " 0.97546658 0.98266604 0.9841101         nan        nan        nan\n",
      " 0.60818997 0.61615056 0.61901262 0.60818997 0.61615056 0.61901262\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98988114 0.99711188 0.99855594\n",
      " 0.97689501 0.9797727  0.9819414         nan        nan        nan\n",
      " 0.61107288 0.60820561 0.6060317  0.61107288 0.60820561 0.6060317\n",
      "        nan        nan        nan 0.98916693 0.99638202 0.99855594\n",
      " 0.97618601 0.98266604 0.9841101         nan        nan        nan\n",
      " 0.60891461 0.61758941 0.61901262 0.60891461 0.61758941 0.61901262\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98988114 0.99711188 0.99855594\n",
      " 0.97761964 0.98049734 0.98339068        nan        nan        nan\n",
      " 0.61107809 0.60892503 0.60458763 0.61107809 0.60892503 0.60458763\n",
      "        nan        nan        nan 0.98916693 0.99638202 0.99855594\n",
      " 0.97618601 0.98266604 0.9841101         nan        nan        nan\n",
      " 0.60891461 0.61758941 0.61973204 0.60891461 0.61758941 0.61973204\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.9222871  0.92228626 0.92257865\n",
      " 0.92345244 0.92287104 0.92374398        nan        nan        nan\n",
      " 0.93131314 0.93160469 0.93189538 0.93131314 0.93160469 0.93189538\n",
      "        nan        nan        nan 0.91268052 0.91209828 0.91209913\n",
      " 0.91675707 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92374483 0.92403553 0.92403553 0.92374483 0.92403553 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92257865 0.92199556 0.92199641\n",
      " 0.92258034 0.92258034 0.92345244        nan        nan        nan\n",
      " 0.93102329 0.93102244 0.93131314 0.93102329 0.93102244 0.93131314\n",
      "        nan        nan        nan 0.91297037 0.91209743 0.91268137\n",
      " 0.91675707 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92345413 0.92374483 0.92403553 0.92345413 0.92374483 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92228795 0.92083107 0.92170486\n",
      " 0.92345244 0.92374314 0.92403383        nan        nan        nan\n",
      " 0.93073174 0.93102244 0.93131314 0.93073174 0.93102244 0.93131314\n",
      "        nan        nan        nan 0.91267967 0.91209743 0.91268137\n",
      " 0.91675707 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92374483 0.92403553 0.92403553 0.92374483 0.92403553 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.95052631\n",
      " 0.9508187  0.94965421 0.94994491        nan        nan        nan\n",
      " 0.9519798  0.9516891  0.95227134 0.9519798  0.9516891  0.95227134\n",
      "        nan        nan        nan 0.94994491 0.94994491 0.95023646\n",
      " 0.95023646 0.94994491 0.95052715        nan        nan        nan\n",
      " 0.95198234 0.95081785 0.95168995 0.95198234 0.95081785 0.95168995\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94965337 0.95023561\n",
      " 0.95081785 0.94994406 0.94994491        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.95198064 0.9516891  0.9516891  0.95198064\n",
      "        nan        nan        nan 0.94994491 0.94965337 0.95023646\n",
      " 0.95023646 0.94965421 0.95081785        nan        nan        nan\n",
      " 0.95198234 0.95110855 0.95168995 0.95198234 0.95110855 0.95168995\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.95023561\n",
      " 0.95110855 0.94994406 0.94994491        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.95198064 0.9516891  0.9516891  0.95198064\n",
      "        nan        nan        nan 0.94994491 0.94965337 0.95023646\n",
      " 0.94994576 0.94994491 0.95052715        nan        nan        nan\n",
      " 0.95198234 0.95081785 0.95168995 0.95198234 0.95081785 0.95168995\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99595783 0.99599016 0.99608718 0.99595783 0.99599016 0.99608718\n",
      "        nan        nan        nan 0.99987064 0.99987064 0.99987064\n",
      " 0.99592546 0.99592546 0.99592546        nan        nan        nan\n",
      " 0.98441343 0.9843811  0.9843811  0.98441343 0.9843811  0.9843811\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99592549 0.99599017 0.99599016 0.99592549 0.99599017 0.99599016\n",
      "        nan        nan        nan 0.99996766 0.99996766 1.\n",
      " 0.99599014 0.99599014 0.99599014        nan        nan        nan\n",
      " 0.9845428  0.98451047 0.98451047 0.9845428  0.98451047 0.98451047\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99586082 0.99592549 0.99599016 0.99586082 0.99592549 0.99599016\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.99602248 0.99602248 0.99602248        nan        nan        nan\n",
      " 0.98457514 0.98454281 0.98454281 0.98457514 0.98454281 0.98454281\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99954726 0.99987064 0.99993533\n",
      " 0.99899753 0.99909453 0.99919155        nan        nan        nan\n",
      " 0.98247308 0.98237607 0.98231139 0.98247308 0.98237607 0.98231139\n",
      "        nan        nan        nan 0.99951493 0.9998383  0.99993533\n",
      " 0.99890051 0.99922386 0.99928856        nan        nan        nan\n",
      " 0.98244076 0.98279645 0.9829258  0.98244076 0.98279645 0.9829258\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99954726 0.99987064 0.99993533\n",
      " 0.99896519 0.99909453 0.99919155        nan        nan        nan\n",
      " 0.98253776 0.98240842 0.9823114  0.98253776 0.98240842 0.9823114\n",
      "        nan        nan        nan 0.99951493 0.9998383  0.99993533\n",
      " 0.99893286 0.99922387 0.99928856        nan        nan        nan\n",
      " 0.9824731  0.98286112 0.9829258  0.9824731  0.98286112 0.9829258\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99954726 0.99987064 0.99993533\n",
      " 0.99899753 0.99912687 0.99925623        nan        nan        nan\n",
      " 0.98253776 0.98244075 0.98224672 0.98253776 0.98244075 0.98224672\n",
      "        nan        nan        nan 0.99951493 0.9998383  0.99993533\n",
      " 0.99893286 0.99922387 0.99928856        nan        nan        nan\n",
      " 0.9824731  0.98286112 0.98295813 0.9824731  0.98286112 0.98295813\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'bootstrap': False, 'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 75}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1345        73\n",
      "pos        46         9\n"
     ]
    }
   ],
   "source": [
    "print(\"Round 2\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [74, 75, 76],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.08282828 0.08112956 0.08154623\n",
      " 0.06738858 0.06738858 0.07002747        nan        nan        nan\n",
      " 0.11064214 0.10871906 0.10871906 0.11064214 0.10871906 0.10871906\n",
      "        nan        nan        nan 0.08319328 0.08235994 0.07767857\n",
      " 0.07976254 0.07976254 0.07997899        nan        nan        nan\n",
      " 0.09305556 0.09305556 0.09305556 0.09305556 0.09305556 0.09305556\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.0700887  0.07330128 0.0700887\n",
      " 0.06863858 0.06772949 0.06911838        nan        nan        nan\n",
      " 0.09953102 0.09760795 0.10841991 0.09953102 0.09760795 0.10841991\n",
      "        nan        nan        nan 0.08797683 0.08759804 0.08329545\n",
      " 0.07309587 0.07309587 0.07331232        nan        nan        nan\n",
      " 0.09083333 0.09083333 0.09083333 0.09083333 0.09083333 0.09083333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.06769554 0.06665968 0.06736874\n",
      " 0.07825397 0.07734488 0.07734488        nan        nan        nan\n",
      " 0.09953102 0.09760795 0.09953102 0.09953102 0.09760795 0.09953102\n",
      "        nan        nan        nan 0.08357207 0.08319328 0.07805736\n",
      " 0.07976254 0.07976254 0.07997899        nan        nan        nan\n",
      " 0.09261905 0.09261905 0.09261905 0.09261905 0.09261905 0.09261905\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98637362 0.98637362 0.98639675 0.98637362 0.98637362 0.98639675\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93596506 0.93596506 0.93596506 0.93596506 0.93596506 0.93596506\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98556292 0.98560466 0.98558081 0.98556292 0.98560466 0.98558081\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93529312 0.93529312 0.93529312 0.93529312 0.93529312 0.93529312\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9855387  0.98555659 0.98555659 0.9855387  0.98555659 0.98555659\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93535284 0.93535284 0.93535284 0.93535284 0.93535284 0.93535284\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9988764  0.99888889 0.9988764  0.9988764  0.99888889 0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9988764  0.99888889 0.9988764  0.9988764  0.99888889 0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9988764  0.99888889 0.9988764  0.9988764  0.99888889 0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.07125    0.07125    0.07125\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333\n",
      "        nan        nan        nan 0.09041667 0.09041667 0.08375\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.07125    0.07125    0.07125    0.07125    0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.065      0.05833333\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.05833333 0.05833333 0.06458333 0.05833333 0.05833333 0.06458333\n",
      "        nan        nan        nan 0.09666667 0.09666667 0.09\n",
      " 0.07125    0.07125    0.07125           nan        nan        nan\n",
      " 0.07125    0.07125    0.07125    0.07125    0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.05833333 0.05833333\n",
      " 0.06458333 0.06458333 0.06458333        nan        nan        nan\n",
      " 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333\n",
      "        nan        nan        nan 0.09041667 0.09041667 0.08375\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.07125    0.07125    0.07125    0.07125    0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9235012  0.9235012  0.92422584 0.9235012  0.9235012  0.92422584\n",
      "        nan        nan        nan 0.99710666 0.99710666 0.99710666\n",
      " 0.90907622 0.90907622 0.90907622        nan        nan        nan\n",
      " 0.69981754 0.69981754 0.69981754 0.69981754 0.69981754 0.69981754\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92277135 0.92421541 0.92349077 0.92277135 0.92421541 0.92349077\n",
      "        nan        nan        nan 0.99927536 0.99927536 0.99927536\n",
      " 0.91052549 0.91052549 0.91052549        nan        nan        nan\n",
      " 0.70344073 0.70344073 0.70344073 0.70344073 0.70344073 0.70344073\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92204671 0.92276613 0.92276613 0.92204671 0.92276613 0.92276613\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.91125013 0.91125013 0.91125013        nan        nan        nan\n",
      " 0.70416536 0.70416536 0.70416536 0.70416536 0.70416536 0.70416536\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99566781 0.99711188 0.99711188\n",
      " 0.97834428 0.9797727  0.98121677        nan        nan        nan\n",
      " 0.60676676 0.60748618 0.60603691 0.60676676 0.60748618 0.60603691\n",
      "        nan        nan        nan 0.99277969 0.99638202 0.99638202\n",
      " 0.98194662 0.98266604 0.98482953        nan        nan        nan\n",
      " 0.61757377 0.61615056 0.61325722 0.61757377 0.61615056 0.61325722\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99566781 0.99711188 0.99711188\n",
      " 0.97761964 0.9797727  0.9819414         nan        nan        nan\n",
      " 0.60675633 0.60820561 0.60458242 0.60675633 0.60820561 0.60458242\n",
      "        nan        nan        nan 0.99277969 0.99638202 0.99638202\n",
      " 0.98266604 0.98266604 0.98554895        nan        nan        nan\n",
      " 0.61829319 0.61758941 0.61325722 0.61829319 0.61758941 0.61325722\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99566781 0.99711188 0.99711188\n",
      " 0.97834428 0.98049734 0.98266604        nan        nan        nan\n",
      " 0.60675633 0.60892503 0.60458242 0.60675633 0.60892503 0.60458242\n",
      "        nan        nan        nan 0.99277969 0.99638202 0.99638202\n",
      " 0.98266604 0.98266604 0.98554895        nan        nan        nan\n",
      " 0.61829319 0.61758941 0.61398186 0.61829319 0.61758941 0.61398186\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.9228685  0.92228626 0.92286935\n",
      " 0.92287104 0.92287104 0.92403468        nan        nan        nan\n",
      " 0.93189538 0.93160469 0.93189623 0.93189538 0.93160469 0.93189623\n",
      "        nan        nan        nan 0.91268052 0.91209828 0.91238898\n",
      " 0.91646552 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92257865 0.92199556 0.92257865\n",
      " 0.92287104 0.92258034 0.92287104        nan        nan        nan\n",
      " 0.93160469 0.93102244 0.93189538 0.93160469 0.93102244 0.93189538\n",
      "        nan        nan        nan 0.91297207 0.91209743 0.91297122\n",
      " 0.91646552 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92374483 0.92374483 0.92374483 0.92374483 0.92374483 0.92374483\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.9222888  0.92083107 0.92228795\n",
      " 0.92403383 0.92374314 0.92374314        nan        nan        nan\n",
      " 0.93102159 0.93102244 0.93102159 0.93102159 0.93102244 0.93102159\n",
      "        nan        nan        nan 0.91297207 0.91209743 0.91268052\n",
      " 0.91646552 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.94994406 0.94994406 0.94994406\n",
      " 0.94994576 0.94965421 0.94994576        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.95198064 0.9516891  0.9516891  0.95198064\n",
      "        nan        nan        nan 0.95052715 0.94994491 0.95052715\n",
      " 0.95023646 0.94994491 0.95023646        nan        nan        nan\n",
      " 0.95140009 0.95081785 0.95052631 0.95140009 0.95081785 0.95052631\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94965337 0.95023561\n",
      " 0.95023646 0.94994406 0.95023561        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.95168995 0.9516891  0.9516891  0.95168995\n",
      "        nan        nan        nan 0.95052715 0.94965337 0.95023561\n",
      " 0.94994576 0.94965421 0.94994576        nan        nan        nan\n",
      " 0.95140009 0.95110855 0.950817   0.95140009 0.95110855 0.950817\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.94994406\n",
      " 0.95023646 0.94994406 0.94994491        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.95198064 0.9516891  0.9516891  0.95198064\n",
      "        nan        nan        nan 0.95052715 0.94965337 0.95023561\n",
      " 0.95023646 0.94994491 0.95023646        nan        nan        nan\n",
      " 0.95140009 0.95081785 0.95052631 0.95140009 0.95081785 0.95052631\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99599016 0.99599016 0.9960225  0.99599016 0.99599016 0.9960225\n",
      "        nan        nan        nan 0.99987064 0.99987064 0.99987064\n",
      " 0.99592546 0.99592546 0.99592546        nan        nan        nan\n",
      " 0.9843811  0.9843811  0.9843811  0.9843811  0.9843811  0.9843811\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9959255  0.99599017 0.99595783 0.9959255  0.99599017 0.99595783\n",
      "        nan        nan        nan 0.99996766 0.99996766 0.99996766\n",
      " 0.99599014 0.99599014 0.99599014        nan        nan        nan\n",
      " 0.98451047 0.98451047 0.98451047 0.98451047 0.98451047 0.98451047\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99589316 0.99592549 0.99592549 0.99589316 0.99592549 0.99592549\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.99602248 0.99602248 0.99602248        nan        nan        nan\n",
      " 0.98454281 0.98454281 0.98454281 0.98454281 0.98454281 0.98454281\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99980597 0.99987064 0.99987064\n",
      " 0.99902986 0.99909453 0.9991592         nan        nan        nan\n",
      " 0.98234375 0.98237607 0.98231142 0.98234375 0.98237607 0.98231142\n",
      "        nan        nan        nan 0.99967662 0.9998383  0.9998383\n",
      " 0.99919154 0.99922386 0.99932088        nan        nan        nan\n",
      " 0.9828611  0.98279645 0.98266712 0.9828611  0.98279645 0.98266712\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99980597 0.99987064 0.99987064\n",
      " 0.99899752 0.99909453 0.99919155        nan        nan        nan\n",
      " 0.98234373 0.98240842 0.98224673 0.98234373 0.98240842 0.98224673\n",
      "        nan        nan        nan 0.99967662 0.9998383  0.9998383\n",
      " 0.99922388 0.99922387 0.99935321        nan        nan        nan\n",
      " 0.98289344 0.98286112 0.98266712 0.98289344 0.98286112 0.98266712\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99980597 0.99987064 0.99987064\n",
      " 0.99902986 0.99912687 0.99922389        nan        nan        nan\n",
      " 0.98234373 0.98244075 0.98224672 0.98234373 0.98244075 0.98224672\n",
      "        nan        nan        nan 0.99967662 0.9998383  0.9998383\n",
      " 0.99922388 0.99922387 0.99935321        nan        nan        nan\n",
      " 0.98289344 0.98286112 0.98269946 0.98289344 0.98286112 0.98269946\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'bootstrap': False, 'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 74}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1346        72\n",
      "pos        46         9\n"
     ]
    }
   ],
   "source": [
    "print(\"Round 3\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [72, 73, 74],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.08282828 0.08154623 0.08282828\n",
      " 0.07002747 0.06647949 0.06738858        nan        nan        nan\n",
      " 0.11064214 0.11064214 0.11064214 0.11064214 0.11064214 0.11064214\n",
      "        nan        nan        nan 0.08319328 0.08319328 0.08319328\n",
      " 0.07976254 0.07976254 0.07976254        nan        nan        nan\n",
      " 0.09305556 0.09305556 0.09305556 0.09305556 0.09305556 0.09305556\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.0700887  0.06880665 0.0700887\n",
      " 0.07002747 0.06786838 0.06863858        nan        nan        nan\n",
      " 0.10841991 0.10841991 0.09953102 0.10841991 0.10841991 0.09953102\n",
      "        nan        nan        nan 0.08843137 0.08759804 0.08797683\n",
      " 0.07309587 0.07309587 0.07309587        nan        nan        nan\n",
      " 0.09083333 0.09083333 0.09083333 0.09083333 0.09083333 0.09083333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.06769554 0.06736874 0.06769554\n",
      " 0.07968254 0.07609488 0.07825397        nan        nan        nan\n",
      " 0.09953102 0.09953102 0.09953102 0.09953102 0.09953102 0.09953102\n",
      "        nan        nan        nan 0.08319328 0.08319328 0.08357207\n",
      " 0.07976254 0.07976254 0.07976254        nan        nan        nan\n",
      " 0.09261905 0.09261905 0.09261905 0.09261905 0.09261905 0.09261905\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98563945 0.98561632 0.98637362 0.98563945 0.98561632 0.98637362\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93686596 0.93596506 0.93596506 0.93686596 0.93596506 0.93596506\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98554329 0.98482947 0.98556292 0.98554329 0.98482947 0.98556292\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93619402 0.93529312 0.93529312 0.93619402 0.93529312 0.93529312\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98475679 0.98475679 0.9855387  0.98475679 0.98475679 0.9855387\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93625374 0.93535284 0.93535284 0.93625374 0.93535284 0.93535284\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99888889 0.9988764  0.9988764  0.99888889 0.9988764  0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99888889 0.9988764  0.9988764  0.99888889 0.9988764  0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99888889 0.9988764  0.9988764  0.99888889 0.9988764  0.9988764\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.07125    0.07125    0.07125\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333\n",
      "        nan        nan        nan 0.09041667 0.09041667 0.09041667\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.07125    0.07125    0.07125    0.07125    0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.05833333 0.05833333\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.06458333 0.06458333 0.05833333 0.06458333 0.06458333 0.05833333\n",
      "        nan        nan        nan 0.09666667 0.09666667 0.09666667\n",
      " 0.07125    0.07125    0.07125           nan        nan        nan\n",
      " 0.07125    0.07125    0.07125    0.07125    0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.05833333 0.05833333\n",
      " 0.06458333 0.06458333 0.06458333        nan        nan        nan\n",
      " 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333\n",
      "        nan        nan        nan 0.09041667 0.09041667 0.09041667\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.07125    0.07125    0.07125    0.07125    0.07125    0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9235012  0.92277656 0.9235012  0.9235012  0.92277656 0.9235012\n",
      "        nan        nan        nan 0.99710666 0.99710666 0.99710666\n",
      " 0.90907622 0.90907622 0.90907622        nan        nan        nan\n",
      " 0.70053696 0.69981754 0.69981754 0.70053696 0.69981754 0.69981754\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92277135 0.92277135 0.92277135 0.92277135 0.92277135 0.92277135\n",
      "        nan        nan        nan 0.99927536 0.99927536 0.99927536\n",
      " 0.91052549 0.91052549 0.91052549        nan        nan        nan\n",
      " 0.70416015 0.70344073 0.70344073 0.70416015 0.70344073 0.70344073\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92059744 0.92059744 0.92204671 0.92059744 0.92059744 0.92204671\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.91125013 0.91125013 0.91125013        nan        nan        nan\n",
      " 0.70488479 0.70416536 0.70416536 0.70488479 0.70416536 0.70416536\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99204463 0.99566781 0.99566781\n",
      " 0.97618079 0.97761964 0.97834428        nan        nan        nan\n",
      " 0.60963925 0.60604212 0.60676676 0.60963925 0.60604212 0.60676676\n",
      "        nan        nan        nan 0.98988635 0.99277969 0.99277969\n",
      " 0.97690022 0.97978313 0.98194662        nan        nan        nan\n",
      " 0.61614013 0.61542592 0.61757377 0.61614013 0.61542592 0.61757377\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99204463 0.99566781 0.99566781\n",
      " 0.97617037 0.97617037 0.97761964        nan        nan        nan\n",
      " 0.61253258 0.60603691 0.60675633 0.61253258 0.60603691 0.60675633\n",
      "        nan        nan        nan 0.98988635 0.99277969 0.99277969\n",
      " 0.97761964 0.97977792 0.98266604        nan        nan        nan\n",
      " 0.61542071 0.61686477 0.61829319 0.61542071 0.61686477 0.61829319\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99204463 0.99566781 0.99566781\n",
      " 0.97761964 0.97761964 0.97834428        nan        nan        nan\n",
      " 0.61180794 0.60603691 0.60675633 0.61180794 0.60603691 0.60675633\n",
      "        nan        nan        nan 0.98988635 0.99277969 0.99277969\n",
      " 0.97761964 0.98050255 0.98266604        nan        nan        nan\n",
      " 0.61614013 0.61686477 0.61829319 0.61614013 0.61686477 0.61829319\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.92316004 0.9225778  0.9228685\n",
      " 0.92374398 0.92258119 0.92287104        nan        nan        nan\n",
      " 0.93189538 0.93189538 0.93189538 0.93189538 0.93189538 0.93189538\n",
      "        nan        nan        nan 0.91238898 0.91238898 0.91268052\n",
      " 0.91617398 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92257865 0.92228795 0.92257865\n",
      " 0.92287104 0.92228965 0.92287104        nan        nan        nan\n",
      " 0.93189538 0.93189538 0.93160469 0.93189538 0.93189538 0.93160469\n",
      "        nan        nan        nan 0.91238813 0.91209743 0.91297207\n",
      " 0.91617398 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92374483 0.92374483 0.92374483 0.92374483 0.92374483 0.92374483\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92228795 0.92170571 0.9222888\n",
      " 0.92403383 0.92287104 0.92403383        nan        nan        nan\n",
      " 0.93102159 0.93102159 0.93102159 0.93102159 0.93102159 0.93102159\n",
      "        nan        nan        nan 0.91209743 0.91209743 0.91297207\n",
      " 0.91617398 0.91617398 0.91646552        nan        nan        nan\n",
      " 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.94994406 0.94994406 0.94994406\n",
      " 0.950528   0.94994576 0.94994576        nan        nan        nan\n",
      " 0.9519798  0.9519798  0.9516891  0.9519798  0.9519798  0.9516891\n",
      "        nan        nan        nan 0.95023646 0.94994576 0.95052715\n",
      " 0.94965506 0.95023646 0.95023646        nan        nan        nan\n",
      " 0.95169164 0.95140094 0.95140009 0.95169164 0.95140094 0.95140009\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94965337 0.95023476\n",
      " 0.95052715 0.950528   0.95023646        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.9516891  0.9516891  0.9516891  0.9516891\n",
      "        nan        nan        nan 0.94994491 0.94965421 0.95052715\n",
      " 0.94965506 0.95023646 0.94994576        nan        nan        nan\n",
      " 0.95169164 0.95169164 0.95140009 0.95169164 0.95169164 0.95140009\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.95023476\n",
      " 0.95081785 0.9508187  0.95023646        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.9516891  0.9516891  0.9516891  0.9516891\n",
      "        nan        nan        nan 0.94994491 0.94965421 0.95052715\n",
      " 0.94965506 0.95023646 0.95023646        nan        nan        nan\n",
      " 0.95169164 0.95140094 0.95140009 0.95169164 0.95140094 0.95140009\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99595782 0.99592548 0.99599016 0.99595782 0.99592548 0.99599016\n",
      "        nan        nan        nan 0.99987064 0.99987064 0.99987064\n",
      " 0.99592546 0.99592546 0.99592546        nan        nan        nan\n",
      " 0.98444576 0.9843811  0.9843811  0.98444576 0.9843811  0.9843811\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99592549 0.99589316 0.9959255  0.99592549 0.99589316 0.9959255\n",
      "        nan        nan        nan 0.99996766 0.99996766 0.99996766\n",
      " 0.99599014 0.99599014 0.99599014        nan        nan        nan\n",
      " 0.98457513 0.98451047 0.98451047 0.98457513 0.98451047 0.98451047\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99579613 0.99579613 0.99589316 0.99579613 0.99579613 0.99589316\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.99602248 0.99602248 0.99602248        nan        nan        nan\n",
      " 0.98460747 0.98454281 0.98454281 0.98460747 0.98454281 0.98454281\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99964426 0.99980597 0.99980597\n",
      " 0.99893283 0.99899751 0.99902986        nan        nan        nan\n",
      " 0.98247309 0.9823114  0.98234375 0.98247309 0.9823114  0.98234375\n",
      "        nan        nan        nan 0.99954726 0.99967662 0.99967662\n",
      " 0.99896515 0.9990945  0.99919154        nan        nan        nan\n",
      " 0.98279647 0.98276412 0.9828611  0.98279647 0.98276412 0.9828611\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99964426 0.99980597 0.99980597\n",
      " 0.99893282 0.99893282 0.99899752        nan        nan        nan\n",
      " 0.98260244 0.9823114  0.98234373 0.98260244 0.9823114  0.98234373\n",
      "        nan        nan        nan 0.99954726 0.99967662 0.99967662\n",
      " 0.9989975  0.9990945  0.99922388        nan        nan        nan\n",
      " 0.98276414 0.98282879 0.98289344 0.98276414 0.98282879 0.98289344\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99964426 0.99980597 0.99980597\n",
      " 0.99899751 0.99899751 0.99902986        nan        nan        nan\n",
      " 0.9825701  0.9823114  0.98234373 0.9825701  0.9823114  0.98234373\n",
      "        nan        nan        nan 0.99954726 0.99967662 0.99967662\n",
      " 0.9989975  0.99912684 0.99922388        nan        nan        nan\n",
      " 0.98279647 0.98282879 0.98289344 0.98279647 0.98282879 0.98289344\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'bootstrap': False, 'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 72}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1346        72\n",
      "pos        46         9\n"
     ]
    }
   ],
   "source": [
    "print(\"Round 4\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [False, True],\n",
    "    'min_samples_split': [1, 2, 3], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'n_estimators' : [70, 71, 72],\n",
    "    'max_depth': [19, 20, 21],\n",
    "    'max_features': [9, 10, 11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.08078866 0.08078866 0.08282828\n",
      " 0.06938154 0.06813154 0.07002747        nan        nan        nan\n",
      " 0.10871906 0.11064214 0.11064214 0.10871906 0.11064214 0.11064214\n",
      "        nan        nan        nan 0.07805736 0.08235994 0.08319328\n",
      " 0.07997899 0.07976254 0.07976254        nan        nan        nan\n",
      " 0.08805556 0.08805556 0.09305556 0.08805556 0.08805556 0.09305556\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.0700887  0.0700887  0.0700887\n",
      " 0.06915043 0.06915043 0.07002747        nan        nan        nan\n",
      " 0.09760795 0.10841991 0.10841991 0.09760795 0.10841991 0.10841991\n",
      "        nan        nan        nan 0.08412879 0.08843137 0.08843137\n",
      " 0.07331232 0.07309587 0.07309587        nan        nan        nan\n",
      " 0.08583333 0.08583333 0.09083333 0.08583333 0.08583333 0.09083333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.06865079 0.06736874 0.06769554\n",
      " 0.07734488 0.07609488 0.07968254        nan        nan        nan\n",
      " 0.09760795 0.09953102 0.09953102 0.09760795 0.09953102 0.09953102\n",
      "        nan        nan        nan 0.07889069 0.08319328 0.08319328\n",
      " 0.07997899 0.07976254 0.07976254        nan        nan        nan\n",
      " 0.08761905 0.08761905 0.09261905 0.08761905 0.08761905 0.09261905\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.05       0.         0.         0.05       0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.05       0.         0.         0.05       0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.05       0.05       0.05       0.05       0.05       0.05\n",
      "        nan        nan        nan 0.05       0.05       0.05\n",
      " 0.05       0.05       0.05              nan        nan        nan\n",
      " 0.05       0.         0.         0.05       0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98638464 0.98562734 0.98563945 0.98638464 0.98562734 0.98563945\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93603745 0.93603745 0.93686596 0.93603745 0.93603745 0.93686596\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.98627675 0.98551944 0.98554329 0.98627675 0.98551944 0.98554329\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93536551 0.93536551 0.93619402 0.93536551 0.93536551 0.93619402\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.9855387  0.98475679 0.98475679 0.9855387  0.98475679 0.98475679\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.93542524 0.93542524 0.93625374 0.93542524 0.93542524 0.93625374\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99886364 0.99886364 0.99888889 0.99886364 0.99886364 0.99888889\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99886364 0.99886364 0.99888889 0.99886364 0.99886364 0.99888889\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99886364 0.99886364 0.99888889 0.99886364 0.99886364 0.99888889\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.07125    0.07125    0.07125\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333 0.06458333\n",
      "        nan        nan        nan 0.08375    0.09041667 0.09041667\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.06458333 0.06458333 0.07125    0.06458333 0.06458333 0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.05833333 0.05833333\n",
      " 0.05833333 0.05833333 0.05833333        nan        nan        nan\n",
      " 0.05833333 0.06458333 0.06458333 0.05833333 0.06458333 0.06458333\n",
      "        nan        nan        nan 0.09       0.09666667 0.09666667\n",
      " 0.07125    0.07125    0.07125           nan        nan        nan\n",
      " 0.06458333 0.06458333 0.07125    0.06458333 0.06458333 0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.05833333 0.05833333 0.05833333\n",
      " 0.06458333 0.06458333 0.06458333        nan        nan        nan\n",
      " 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333 0.05833333\n",
      "        nan        nan        nan 0.08375    0.09041667 0.09041667\n",
      " 0.0775     0.0775     0.0775            nan        nan        nan\n",
      " 0.06458333 0.06458333 0.07125    0.06458333 0.06458333 0.07125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.00666667 0.         0.         0.00666667 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.00666667 0.         0.         0.00666667 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      "        nan        nan        nan 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667 0.00666667        nan        nan        nan\n",
      " 0.00666667 0.         0.         0.00666667 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92278177 0.92278177 0.9235012  0.92278177 0.92278177 0.9235012\n",
      "        nan        nan        nan 0.99710666 0.99710666 0.99710666\n",
      " 0.90907622 0.90907622 0.90907622        nan        nan        nan\n",
      " 0.70053696 0.70053696 0.70053696 0.70053696 0.70053696 0.70053696\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92204671 0.92204671 0.92277135 0.92204671 0.92204671 0.92277135\n",
      "        nan        nan        nan 0.99927536 0.99927536 0.99927536\n",
      " 0.91052549 0.91052549 0.91052549        nan        nan        nan\n",
      " 0.70416015 0.70416015 0.70416015 0.70416015 0.70416015 0.70416015\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.92132207 0.92059744 0.92059744 0.92132207 0.92059744 0.92059744\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.91125013 0.91125013 0.91125013        nan        nan        nan\n",
      " 0.70488479 0.70488479 0.70488479 0.70488479 0.70488479 0.70488479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98988114 0.99566781 0.99204463\n",
      " 0.97761964 0.97906892 0.97618079        nan        nan        nan\n",
      " 0.60962882 0.61035346 0.60963925 0.60962882 0.61035346 0.60963925\n",
      "        nan        nan        nan 0.98916693 0.99206026 0.98988635\n",
      " 0.97546658 0.97763007 0.97690022        nan        nan        nan\n",
      " 0.60818997 0.61034824 0.61614013 0.60818997 0.61034824 0.61614013\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98988114 0.99566781 0.99204463\n",
      " 0.97689501 0.97834428 0.97617037        nan        nan        nan\n",
      " 0.61107288 0.60963925 0.61253258 0.61107288 0.60963925 0.61253258\n",
      "        nan        nan        nan 0.98916693 0.99206026 0.98988635\n",
      " 0.97618601 0.97834428 0.97761964        nan        nan        nan\n",
      " 0.60891461 0.61034303 0.61542071 0.60891461 0.61034303 0.61542071\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98988114 0.99566781 0.99204463\n",
      " 0.97761964 0.97906892 0.97761964        nan        nan        nan\n",
      " 0.61107809 0.60819518 0.61180794 0.61107809 0.60819518 0.61180794\n",
      "        nan        nan        nan 0.98916693 0.99206026 0.98988635\n",
      " 0.97618601 0.97906892 0.97761964        nan        nan        nan\n",
      " 0.60891461 0.61034303 0.61614013 0.60891461 0.61034303 0.61614013\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.9222871  0.9222871  0.92316004\n",
      " 0.92345244 0.92345328 0.92374398        nan        nan        nan\n",
      " 0.93131314 0.93189538 0.93189538 0.93131314 0.93189538 0.93189538\n",
      "        nan        nan        nan 0.91268052 0.91209828 0.91238898\n",
      " 0.91675707 0.91617398 0.91617398        nan        nan        nan\n",
      " 0.92374483 0.92374483 0.92403553 0.92374483 0.92374483 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92257865 0.92257865 0.92257865\n",
      " 0.92258034 0.92287104 0.92287104        nan        nan        nan\n",
      " 0.93102329 0.93160469 0.93189538 0.93102329 0.93160469 0.93189538\n",
      "        nan        nan        nan 0.91297037 0.91238813 0.91238813\n",
      " 0.91675707 0.91617398 0.91617398        nan        nan        nan\n",
      " 0.92345413 0.92345413 0.92374483 0.92345413 0.92345413 0.92374483\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92228795 0.92141416 0.92228795\n",
      " 0.92345244 0.92316174 0.92403383        nan        nan        nan\n",
      " 0.93073174 0.9307309  0.93102159 0.93073174 0.9307309  0.93102159\n",
      "        nan        nan        nan 0.91267967 0.91209743 0.91209743\n",
      " 0.91675707 0.91617398 0.91617398        nan        nan        nan\n",
      " 0.92374483 0.92374483 0.92403553 0.92374483 0.92374483 0.92403553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.94994406\n",
      " 0.9508187  0.9502373  0.950528          nan        nan        nan\n",
      " 0.9519798  0.9516891  0.9519798  0.9519798  0.9516891  0.9519798\n",
      "        nan        nan        nan 0.94994491 0.94965337 0.95023646\n",
      " 0.95023646 0.95023646 0.94965506        nan        nan        nan\n",
      " 0.95198234 0.95140009 0.95169164 0.95198234 0.95140009 0.95169164\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.95023476\n",
      " 0.95081785 0.95081785 0.95052715        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.9516891  0.9516891  0.9516891  0.9516891\n",
      "        nan        nan        nan 0.94994491 0.94965337 0.94994491\n",
      " 0.95023646 0.95023646 0.94965506        nan        nan        nan\n",
      " 0.95198234 0.95140009 0.95169164 0.95198234 0.95140009 0.95169164\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95023476 0.94994406 0.95023476\n",
      " 0.95110855 0.95110855 0.95081785        nan        nan        nan\n",
      " 0.9516891  0.9516891  0.9516891  0.9516891  0.9516891  0.9516891\n",
      "        nan        nan        nan 0.94994491 0.94965337 0.94994491\n",
      " 0.94994576 0.94994576 0.94965506        nan        nan        nan\n",
      " 0.95198234 0.95140009 0.95169164 0.95198234 0.95140009 0.95169164\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99595783 0.99592549 0.99595782 0.99595783 0.99592549 0.99595782\n",
      "        nan        nan        nan 0.99987064 0.99987064 0.99987064\n",
      " 0.99592546 0.99592546 0.99592546        nan        nan        nan\n",
      " 0.98441343 0.98441343 0.98444576 0.98441343 0.98441343 0.98444576\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99592549 0.99589315 0.99592549 0.99592549 0.99589315 0.99592549\n",
      "        nan        nan        nan 0.99996766 0.99996766 0.99996766\n",
      " 0.99599014 0.99599014 0.99599014        nan        nan        nan\n",
      " 0.9845428  0.9845428  0.98457513 0.9845428  0.9845428  0.98457513\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99586082 0.99579613 0.99579613 0.99586082 0.99579613 0.99579613\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.99602248 0.99602248 0.99602248        nan        nan        nan\n",
      " 0.98457514 0.98457514 0.98460747 0.98457514 0.98457514 0.98460747\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99954726 0.99980597 0.99964426\n",
      " 0.99899753 0.9990622  0.99893283        nan        nan        nan\n",
      " 0.98247308 0.98250541 0.98247309 0.98247308 0.98250541 0.98247309\n",
      "        nan        nan        nan 0.99951493 0.99964429 0.99954726\n",
      " 0.99890051 0.99899753 0.99896515        nan        nan        nan\n",
      " 0.98244076 0.98253775 0.98279647 0.98244076 0.98253775 0.98279647\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99954726 0.99980597 0.99964426\n",
      " 0.99896519 0.99902986 0.99893282        nan        nan        nan\n",
      " 0.98253776 0.98247308 0.98260244 0.98253776 0.98247308 0.98260244\n",
      "        nan        nan        nan 0.99951493 0.99964429 0.99954726\n",
      " 0.99893286 0.99902986 0.9989975         nan        nan        nan\n",
      " 0.9824731  0.98253775 0.98276414 0.9824731  0.98253775 0.98276414\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.99954726 0.99980597 0.99964426\n",
      " 0.99899753 0.9990622  0.99899751        nan        nan        nan\n",
      " 0.98253776 0.98240841 0.9825701  0.98253776 0.98240841 0.9825701\n",
      "        nan        nan        nan 0.99951493 0.99964429 0.99954726\n",
      " 0.99893286 0.9990622  0.9989975         nan        nan        nan\n",
      " 0.9824731  0.98253775 0.98279647 0.9824731  0.98253775 0.98279647\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'bootstrap': False, 'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 71}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1345        73\n",
      "pos        46         9\n"
     ]
    }
   ],
   "source": [
    "print(\"Round 5\")\n",
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## . Test to see which parameters achieve the largest recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')\n",
    "grid_search_clf\n",
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "results = results.sort_values(by='mean_test_precision_score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
